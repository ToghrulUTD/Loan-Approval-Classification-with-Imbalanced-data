{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "62834763",
      "metadata": {
        "id": "62834763"
      },
      "source": [
        "# Project Starter - Simple Baseline Logistic and Decision Tree Models\n",
        "\n",
        "\n",
        "\n",
        "The project will include following tasks:\n",
        "- Load dataset\n",
        "- Clean up the data:\n",
        "    - Encode replace missing values\n",
        "    - Replace features values that appear incorrect\n",
        "- Encode categorical variables\n",
        "- Split dataset to Train/Test/Validation\n",
        "- Add engineered features\n",
        "- Train and tune ML model\n",
        "- Provide final metrics using Validation dataset\n",
        "\n",
        " As part of your deliverables, I will be create scoring function. The scoring function will perform following:\n",
        "- Accept dataset in the same format as provided with the project, minus \"MIS_Status\" column\n",
        "- Load trained model and any encoders that are needed to transform data\n",
        "- Transform dataset into format that can be scored with the trained model\n",
        "- Score the dataset and return the results, for each record\n",
        "    - Record ID\n",
        "    - Record label as determined by final model (0 or 1)\n",
        "    - If the model returns probabilities, assign label based on maximum F1 threshold\n",
        "\n",
        "\n",
        "Deliverables:\n",
        "- Jupyter notebook with complete code to manipulate data, train and tune final model\n",
        "- Model and any potential encoders in the \"pkl\" format\n",
        "- Scoring function that will load final model and encoders\n",
        "\n",
        "\n",
        "The notebook includes explanations about the code and is designed to be easily followed and results replicated."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c341cb74",
      "metadata": {
        "id": "c341cb74"
      },
      "source": [
        "## Dataset description\n",
        "\n",
        "The dataset is from the U.S. Small Business Administration (SBA) The U.S. SBA was founded in 1953 on the principle of promoting and assisting small enterprises in the U.S. credit market (SBA Overview and History, US Small Business Administration (2015)). Small businesses have been a primary source of job creation in the United States; therefore, fostering small business formation and growth has social benefits by creating job opportunities and reducing unemployment. There have been many success stories of start-ups receiving SBA loan guarantees such as FedEx and Apple Computer. However, there have also been stories of small businesses and/or start-ups that have defaulted on their SBA-guaranteed loans.  \n",
        "More info on the original dataset: https://www.kaggle.com/mirbektoktogaraev/should-this-loan-be-approved-or-denied\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c9b618",
      "metadata": {
        "id": "a0c9b618"
      },
      "source": [
        "## Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca7e035",
      "metadata": {
        "id": "3ca7e035",
        "outputId": "d31f1211-6b9f-4c0a-a6ba-f96e13ec49f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 1500)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#Extend cell width\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "from category_encoders.target_encoder import TargetEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb889838",
      "metadata": {
        "id": "eb889838"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Created on Mon Mar 18 18:25:50 2019\n",
        "\n",
        "@author: Uri Smashnov\n",
        "\n",
        "Purpose: Analyze input Pandas DataFrame and return stats per column\n",
        "Details: The function calculates levels for categorical variables and allows to analyze summarized information\n",
        "\n",
        "To view wide table set following Pandas options:\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('max_colwidth',200)\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "def describe_more(df,normalize_ind=False, weight_column=None, skip_columns=[], dropna=True):\n",
        "    var = [] ; l = [] ; t = []; unq =[]; min_l = []; max_l = [];\n",
        "    assert isinstance(skip_columns, list), \"Argument skip_columns should be list\"\n",
        "    if weight_column is not None:\n",
        "        if weight_column not in list(df.columns):\n",
        "            raise AssertionError('weight_column is not a valid column name in the input DataFrame')\n",
        "      \n",
        "    for x in df:\n",
        "        if x in skip_columns:\n",
        "            pass\n",
        "        else:\n",
        "            var.append( x )\n",
        "            uniq_counts = len(pd.value_counts(df[x],dropna=dropna))\n",
        "            uniq_counts = len(pd.value_counts(df[x], dropna=dropna)[pd.value_counts(df[x],dropna=dropna)>0])\n",
        "            l.append(uniq_counts)\n",
        "            t.append( df[ x ].dtypes )\n",
        "            min_l.append(df[x].apply(str).str.len().min())\n",
        "            max_l.append(df[x].apply(str).str.len().max())\n",
        "            if weight_column is not None and x not in skip_columns:\n",
        "                df2 = df.groupby(x).agg({weight_column: 'sum'}).sort_values(weight_column, ascending=False)\n",
        "                df2['authtrans_vts_cnt']=((df2[weight_column])/df2[weight_column].sum()).round(2)\n",
        "                unq.append(df2.head(n=100).to_dict()[weight_column])\n",
        "            else:\n",
        "                df_cat_d = df[x].value_counts(normalize=normalize_ind,dropna=dropna).round(decimals=2)\n",
        "                df_cat_d = df_cat_d[df_cat_d>0]\n",
        "                #unq.append(df[x].value_counts().iloc[0:100].to_dict())\n",
        "                unq.append(df_cat_d.iloc[0:100].to_dict())\n",
        "            \n",
        "    levels = pd.DataFrame( { 'A_Variable' : var , 'Levels' : l , 'Datatype' : t ,\n",
        "                             'Min Length' : min_l,\n",
        "                             'Max Length': max_l,\n",
        "                             'Level_Values' : unq} )\n",
        "    #levels.sort_values( by = 'Levels' , inplace = True )\n",
        "    return levels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cee2c254",
      "metadata": {
        "id": "cee2c254"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a19bd163",
      "metadata": {
        "id": "a19bd163"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('SBA_loans_project_1.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2301a5ed",
      "metadata": {
        "id": "2301a5ed",
        "outputId": "800dd2c5-0907-4439-9ae6-b8c09be1f134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (809247, 20)\n"
          ]
        }
      ],
      "source": [
        "print(\"Data shape:\", data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cdbf93f",
      "metadata": {
        "id": "4cdbf93f"
      },
      "source": [
        "### I will load the data for each model seperately as I may use different feature engineering and scalers for different models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab8b4aea",
      "metadata": {
        "id": "ab8b4aea"
      },
      "source": [
        "**Review dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "547f9eb1",
      "metadata": {
        "id": "547f9eb1",
        "outputId": "0239d821-cf4e-4de7-d1a9-e64c21679d7e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A_Variable</th>\n",
              "      <th>Levels</th>\n",
              "      <th>Datatype</th>\n",
              "      <th>Min Length</th>\n",
              "      <th>Max Length</th>\n",
              "      <th>Level_Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>City</td>\n",
              "      <td>31320</td>\n",
              "      <td>object</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>{'LOS ANGELES': 10372, 'HOUSTON': 9260, 'NEW Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>State</td>\n",
              "      <td>51</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>{'CA': 117341, 'TX': 63425, 'NY': 51877, 'FL':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zip</td>\n",
              "      <td>32731</td>\n",
              "      <td>int64</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>{10001: 841, 90015: 830, 93401: 729, 90010: 65...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bank</td>\n",
              "      <td>5716</td>\n",
              "      <td>object</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>{'BANK OF AMERICA NATL ASSOC': 78111, 'WELLS F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BankState</td>\n",
              "      <td>55</td>\n",
              "      <td>object</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>{'CA': 106293, 'NC': 71557, 'IL': 59258, 'OH':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NAICS</td>\n",
              "      <td>1307</td>\n",
              "      <td>int64</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>{0: 181845, 722110: 25217, 722211: 17476, 8111...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Term</td>\n",
              "      <td>407</td>\n",
              "      <td>int64</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>{84: 207228, 60: 80965, 240: 77385, 120: 69852...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NoEmp</td>\n",
              "      <td>581</td>\n",
              "      <td>int64</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>{1: 138836, 2: 124470, 3: 81466, 4: 66306, 5: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NewExist</td>\n",
              "      <td>3</td>\n",
              "      <td>float64</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>{1.0: 580478, 2.0: 227709, 0.0: 932}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CreateJob</td>\n",
              "      <td>234</td>\n",
              "      <td>int64</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>{0: 566148, 1: 56789, 2: 52162, 3: 25945, 4: 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RetainedJob</td>\n",
              "      <td>345</td>\n",
              "      <td>int64</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>{0: 396287, 1: 79893, 2: 69149, 3: 44941, 4: 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>FranchiseCode</td>\n",
              "      <td>2684</td>\n",
              "      <td>int64</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>{1: 574731, 0: 187961, 78760: 3043, 68020: 173...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>UrbanRural</td>\n",
              "      <td>3</td>\n",
              "      <td>int64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>{1: 423681, 0: 290804, 2: 94762}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RevLineCr</td>\n",
              "      <td>16</td>\n",
              "      <td>object</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>{'N': 378424, '0': 231967, 'Y': 181011, 'T': 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>LowDoc</td>\n",
              "      <td>8</td>\n",
              "      <td>object</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>{'N': 704515, 'Y': 99339, '0': 1343, 'C': 681,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>DisbursementGross</td>\n",
              "      <td>110579</td>\n",
              "      <td>object</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>{'$50,000.00 ': 39328, '$100,000.00 ': 33116, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>BalanceGross</td>\n",
              "      <td>13</td>\n",
              "      <td>object</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>{'$0.00 ': 809235, '$41,509.00 ': 1, '$115,820...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>GrAppv</td>\n",
              "      <td>20724</td>\n",
              "      <td>object</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>{'$50,000.00 ': 62264, '$25,000.00 ': 46168, '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SBA_Appv</td>\n",
              "      <td>35896</td>\n",
              "      <td>object</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>{'$25,000.00 ': 44418, '$12,500.00 ': 36115, '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>MIS_Status</td>\n",
              "      <td>2</td>\n",
              "      <td>object</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>{'P I F': 665576, 'CHGOFF': 141849}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           A_Variable  Levels Datatype  Min Length  Max Length  \\\n",
              "0                City   31320   object           1          30   \n",
              "1               State      51   object           2           3   \n",
              "2                 Zip   32731    int64           1           5   \n",
              "3                Bank    5716   object           3          30   \n",
              "4           BankState      55   object           2           3   \n",
              "5               NAICS    1307    int64           1           6   \n",
              "6                Term     407    int64           1           3   \n",
              "7               NoEmp     581    int64           1           4   \n",
              "8            NewExist       3  float64           3           3   \n",
              "9           CreateJob     234    int64           1           4   \n",
              "10        RetainedJob     345    int64           1           4   \n",
              "11      FranchiseCode    2684    int64           1           5   \n",
              "12         UrbanRural       3    int64           1           1   \n",
              "13          RevLineCr      16   object           1           3   \n",
              "14             LowDoc       8   object           1           3   \n",
              "15  DisbursementGross  110579   object           6          15   \n",
              "16       BalanceGross      13   object           6          12   \n",
              "17             GrAppv   20724   object           8          14   \n",
              "18           SBA_Appv   35896   object           8          14   \n",
              "19         MIS_Status       2   object           3           6   \n",
              "\n",
              "                                         Level_Values  \n",
              "0   {'LOS ANGELES': 10372, 'HOUSTON': 9260, 'NEW Y...  \n",
              "1   {'CA': 117341, 'TX': 63425, 'NY': 51877, 'FL':...  \n",
              "2   {10001: 841, 90015: 830, 93401: 729, 90010: 65...  \n",
              "3   {'BANK OF AMERICA NATL ASSOC': 78111, 'WELLS F...  \n",
              "4   {'CA': 106293, 'NC': 71557, 'IL': 59258, 'OH':...  \n",
              "5   {0: 181845, 722110: 25217, 722211: 17476, 8111...  \n",
              "6   {84: 207228, 60: 80965, 240: 77385, 120: 69852...  \n",
              "7   {1: 138836, 2: 124470, 3: 81466, 4: 66306, 5: ...  \n",
              "8                {1.0: 580478, 2.0: 227709, 0.0: 932}  \n",
              "9   {0: 566148, 1: 56789, 2: 52162, 3: 25945, 4: 1...  \n",
              "10  {0: 396287, 1: 79893, 2: 69149, 3: 44941, 4: 3...  \n",
              "11  {1: 574731, 0: 187961, 78760: 3043, 68020: 173...  \n",
              "12                   {1: 423681, 0: 290804, 2: 94762}  \n",
              "13  {'N': 378424, '0': 231967, 'Y': 181011, 'T': 1...  \n",
              "14  {'N': 704515, 'Y': 99339, '0': 1343, 'C': 681,...  \n",
              "15  {'$50,000.00 ': 39328, '$100,000.00 ': 33116, ...  \n",
              "16  {'$0.00 ': 809235, '$41,509.00 ': 1, '$115,820...  \n",
              "17  {'$50,000.00 ': 62264, '$25,000.00 ': 46168, '...  \n",
              "18  {'$25,000.00 ': 44418, '$12,500.00 ': 36115, '...  \n",
              "19                {'P I F': 665576, 'CHGOFF': 141849}  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "desc_df = describe_more(data)\n",
        "desc_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe1af41",
      "metadata": {
        "id": "5fe1af41"
      },
      "source": [
        "## Dataset preparation and clean-up\n",
        "\n",
        "Modify and clean-up the dataset as following:\n",
        "- Replace encode Na/Null values\n",
        "- Convert the strings styled as '$XXXX.XX' to float values. Columns = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
        "- Convert MIS_Status to 0/1. Make value \"CHGOFF\" as 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9f9eaa",
      "metadata": {
        "id": "0f9f9eaa"
      },
      "outputs": [],
      "source": [
        "def clean_data(data):\n",
        "    value_to_fill={}\n",
        "    for col in data.columns:\n",
        "        if data[col].dtype=='object':\n",
        "            value_to_fill[col]='Missing'\n",
        "        else:\n",
        "            value_to_fill[col]=0\n",
        "    data.fillna(value=value_to_fill,inplace=True)\n",
        "\n",
        "    Columns = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
        "\n",
        "    for col in Columns:\n",
        "        for char in ['$',',']:\n",
        "            data[col] = data[col].str.replace(char,'')\n",
        "        data[col]=data[col].astype(float)\n",
        "\n",
        "    #LowDoc and RevLineCr can only be 'Y' or 'N', i.e., yes or no.\n",
        "    for col in ['LowDoc' , 'RevLineCr']:\n",
        "        data[col]=data[col].agg(lambda x: 'Missing' if x not in ['N','Y'] else x)\n",
        "\n",
        "    # NAICS code must be 6 digit code: replace smaller digits with 0.\n",
        "    data['NAICS']=data['NAICS'].agg(lambda x: x if len(str(x))==6 else 0)\n",
        "\n",
        "    # Franchise code 0 and 1 means 'NO Franchise'\n",
        "    data['FranchiseCode']=data['FranchiseCode'].agg(lambda x: 1 if x==1 else x)\n",
        "    \n",
        "    # Convert NAICS, FranchaiseCode, Zip,'NewExist' and 'UrbanRural' into object type\n",
        "    for col in ['FranchiseCode','NAICS','Zip','NewExist','UrbanRural']:\n",
        "        data[col]=data[col].astype(object)\n",
        "\n",
        "    #Convert MIS into binary\n",
        "    MIS_dict={'P I F': 0, 'CHGOFF': 1, 'Missing':0}\n",
        "    data['MIS_Status'].replace(MIS_dict,inplace=True)\n",
        "    return(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607dee21",
      "metadata": {
        "id": "607dee21"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15dc9050",
      "metadata": {
        "id": "15dc9050"
      },
      "outputs": [],
      "source": [
        "def feature_engineer(data):\n",
        "    ''' Creates two new features: Industry and Montly_disumbersement.\n",
        "        Input: Cleaned SBA Dataframe\n",
        "        Output: Dataframe with feature engineered columns\n",
        "    '''\n",
        "    industry_codes=['11','21','22','23','31','32','33','42','44','45','48','49','51',\n",
        "                    '52','53','54','55','56','61','62','71','72','81','0']\n",
        "    industry_dict={'11':'Agriculture, forestry, fishing and hunting',\n",
        "        '21':'Mining, quarrying, and oil and gas extraction',\n",
        "        '22':'Utilities',\n",
        "        '23':'Construction',\n",
        "        '31':'Manufacturing',\n",
        "        '32':'Manufacturing',\n",
        "        '33':'Manufacturing',\n",
        "        '42':'Wholesale trade',\n",
        "        '44':'Retail trade',\n",
        "        '45':'Retail trade',\n",
        "        '48':'Transportation and warehousing',\n",
        "        '49':'Transportation and warehousing',\n",
        "        '51':'Information',\n",
        "        '52':'Finance and insurance',\n",
        "        '53':'Real estate and rental and leasing',\n",
        "        '54':'Professional, scientific, and technical services',\n",
        "        '55':'Management of companies and enterprises',\n",
        "        '56':'Administrative and support and waste management and remediation services',\n",
        "        '61':'Educational services',\n",
        "        '62':'Health care and social assistance',\n",
        "        '71':'Arts, entertainment, and recreation',\n",
        "        '72':'Accommodation and food services',\n",
        "        '81':'Other services (except public administration) 92 Public administration',\n",
        "        '0':'undefined'}\n",
        "    # Function to create Industry column from NAICS columns\n",
        "    def add_Industry_col(data):\n",
        "        data['Industry']=data['NAICS'].astype('string')\n",
        "        data['Industry']=data['Industry'].apply(lambda x: x[:2] if x[:2] in industry_codes else  x=='0' )\n",
        "        data['Industry'].replace(industry_dict,inplace=True)\n",
        "        return data\n",
        "    \n",
        "    \n",
        "    # Function to create monthtly disumbersement column.\n",
        "    def monthly_payment(total,terms):\n",
        "        if terms==0:\n",
        "            monthly=total\n",
        "        else:\n",
        "            monthly=total/terms\n",
        "        return monthly\n",
        "    \n",
        "    data= add_Industry_col(data)\n",
        "    data['monthly_disumb'] = data.apply(lambda x: monthly_payment(x.DisbursementGross, x.Term), axis=1)\n",
        "    return data\n",
        "\n",
        "#Create a function for binning numerical columns\n",
        "def bin_numerical_cols(data, drop=True,number_of_bins=40):\n",
        "    '''\n",
        "    Create bins for numerical variables based on quantiles\n",
        "    \n",
        "    Inputs:\n",
        "        data:  Cleaned and feature engineered SBA dataframe\n",
        "        drop:  True or False/ True drops binned numerical columns\n",
        "        number_of_bins: Maximum number of quantile bins\n",
        "    \n",
        "    Output: Dataframe with bin columns\n",
        "    '''\n",
        "    #This can also be done with if condition to determine numerical columns\n",
        "    numerical_cols=['Term','NoEmp','CreateJob','RetainedJob','DisbursementGross',\n",
        "                       'BalanceGross','GrAppv','SBA_Appv','monthly_disumb']\n",
        "    bin_columns=[]\n",
        "    binned_col=[]\n",
        "    bins_for_cols={}\n",
        "    for col in numerical_cols:\n",
        "        bins=[np.percentile(data[col].values,i) for i in np.linspace(2.5,97.5,number_of_bins-1)]\n",
        "        bins=np.concatenate([[-np.inf],bins,[np.inf]])\n",
        "        bins_for_cols[col]=bins\n",
        "        data[col+'_bin']=pd.cut(data[col], bins,duplicates='drop')\n",
        "        data[col+'_bin']=data[col+'_bin'].astype('object')\n",
        "        binned_col.append(col)\n",
        "        bin_columns.append(col+'_bin')\n",
        "    if drop==True:\n",
        "        data.drop(columns=binned_col,inplace=True)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7f21dcf",
      "metadata": {
        "id": "b7f21dcf"
      },
      "source": [
        "## Categorical variables encoding\n",
        "\n",
        "Encoding categorical variables using the techniques below.\n",
        "- One-hot-encoder for variables with less than 10 valid values. Name your new columns \"Original_name\"_valid_value\n",
        "- (If using sklearn) Target encoder from the following library: https://contrib.scikit-learn.org/category_encoders/index.html . Name your new column \"Original_name\"_trg\n",
        "- (If using H2O) Use H2O target encoder\n",
        "\n",
        "\n",
        "Example of use for target encoder:\n",
        "```\n",
        "import category_encoders as ce\n",
        "\n",
        "encoder = ce.TargetEncoder(cols=[...])\n",
        "\n",
        "encoder.fit(X, y)\n",
        "X_cleaned = encoder.transform(X_dirty)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fef1d2e",
      "metadata": {
        "id": "4fef1d2e"
      },
      "outputs": [],
      "source": [
        "#Import and run the created functions on the data\n",
        "data=pd.read_csv('SBA_loans_project_1.zip')\n",
        "data=clean_data(data)\n",
        "data=feature_engineer(data)\n",
        "data=bin_numerical_cols(data,drop=False,number_of_bins=30)\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(data.drop(columns=['MIS_Status'])\n",
        "                                               ,data['MIS_Status'].values.reshape(-1,1), test_size=0.2, random_state=0)\n",
        "X_train=X_train.reset_index(drop=True)\n",
        "X_test=X_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dd57849",
      "metadata": {
        "id": "0dd57849",
        "outputId": "5293f62a-62f5-4a32-a066-bdd13bbcf463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target encoding of City:\n",
            "Target encoding of State:\n",
            "Target encoding of Zip:\n",
            "Target encoding of Bank:\n",
            "Target encoding of BankState:\n",
            "Target encoding of NAICS:\n",
            "Onehot encoding of NewExist:\n",
            "Target encoding of FranchiseCode:\n",
            "Onehot encoding of UrbanRural:\n",
            "Onehot encoding of RevLineCr:\n",
            "Onehot encoding of LowDoc:\n",
            "Target encoding of Industry:\n",
            "Target encoding of Term_bin:\n",
            "Target encoding of NoEmp_bin:\n",
            "Onehot encoding of CreateJob_bin:\n",
            "Target encoding of RetainedJob_bin:\n",
            "Target encoding of DisbursementGross_bin:\n",
            "Onehot encoding of BalanceGross_bin:\n",
            "Target encoding of GrAppv_bin:\n",
            "Target encoding of SBA_Appv_bin:\n",
            "Target encoding of monthly_disumb_bin:\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Categorical encoders disctionary\n",
        "column_encoders=[]\n",
        "#New categorical (encoded) columns\n",
        "encoded_columns=[]\n",
        "#Columns to drop from ML models\n",
        "columns_to_drop=[]\n",
        "\n",
        "for col in data.drop(columns='MIS_Status').columns:\n",
        "    if data[col].dtype=='object':\n",
        "        if data[col].nunique() <10:\n",
        "            print('Onehot encoding of {}:'.format(col))\n",
        "            enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "            '''Encode Training data'''\n",
        "            enc.fit(X_train[[col]])\n",
        "            result = enc.transform(X_train[[col]])\n",
        "            ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
        "            result_train=pd.DataFrame(enc.transform(X_train[[col]]),columns=ohe_columns)\n",
        "            X_train = pd.concat([X_train, result_train], axis=1)\n",
        "            '''Encode Test data'''\n",
        "            result_test=pd.DataFrame(enc.transform(X_test[[col]]),columns=ohe_columns)\n",
        "            X_test = pd.concat([X_test,result_test],axis=1)\n",
        "            encoded_columns = encoded_columns + ohe_columns \n",
        "            column_encoders.append([deepcopy(enc),'ohe'])\n",
        "        else:\n",
        "            print('Target encoding of {}:'.format(col))\n",
        "            te=TargetEncoder(smoothing=0.1,handle_unknown='value')\n",
        "            '''Fit and transform Training data'''\n",
        "            te.fit(X_train[col],y_train)\n",
        "            new_col=col+'_trg'\n",
        "            X_train[new_col]=te.transform(X_train[col])\n",
        "            '''Transform Test data'''\n",
        "            X_test[new_col]=te.transform(X_test[col])                         \n",
        "            encoded_columns.append(new_col)\n",
        "            column_encoders.append([deepcopy(te),'trg'])\n",
        "            \n",
        "        columns_to_drop.append(col)\n",
        "        \n",
        "# Drop encoded columns\n",
        "X_train.drop(columns=columns_to_drop,inplace=True)\n",
        "X_test.drop(columns=columns_to_drop,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb0bfa4",
      "metadata": {
        "id": "7bb0bfa4"
      },
      "source": [
        "# Model Training\n",
        "\n",
        "Depending on the model of your choice, we might need to use appropriate scaler for numerical variables.\n",
        "\n",
        "We will train at least two types of models from the below list.\n",
        "From sklearn libraries:\n",
        "- Logistic regression\n",
        "- SVM\n",
        "- Decision Tree\n",
        "\n",
        "From H2O libraries:\n",
        "- GLM\n",
        "- SVM\n",
        "- Naïve Bayes Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a88e52c8",
      "metadata": {
        "id": "a88e52c8"
      },
      "source": [
        "# First Model. Decision Tree with Binned numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e19e26",
      "metadata": {
        "id": "f7e19e26",
        "outputId": "1aae8db1-0d81-43d0-cfa9-3abb2ac66e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weight  balanced\n",
            "{'ccp_alpha': 0.0, 'max_depth': 20.0} 0.9309651382407252\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95    133561\n",
            "           1       0.74      0.84      0.79     28289\n",
            "\n",
            "    accuracy                           0.92    161850\n",
            "   macro avg       0.85      0.89      0.87    161850\n",
            "weighted avg       0.93      0.92      0.92    161850\n",
            "\n",
            "Class weight  None\n",
            "{'ccp_alpha': 0.0, 'max_depth': 14.0} 0.9398847975207385\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    133561\n",
            "           1       0.83      0.79      0.81     28289\n",
            "\n",
            "    accuracy                           0.93    161850\n",
            "   macro avg       0.89      0.88      0.88    161850\n",
            "weighted avg       0.93      0.93      0.93    161850\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for balance in ['balanced',None]:\n",
        "    print('Class weight ',balance)\n",
        "    parameters={'max_depth':np.linspace(11,20,10),'ccp_alpha':np.linspace(0,0.001,5)}\n",
        "    dtc = DecisionTreeClassifier(criterion='gini',random_state=0,class_weight=balance)\n",
        "    clf = GridSearchCV(dtc, parameters, cv=4,scoring='f1_weighted',n_jobs=-1)\n",
        "    clf.fit(X_train, y_train)\n",
        "    print(clf.best_params_,clf.best_score_)\n",
        "    print(classification_report(y_test,clf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f062297c",
      "metadata": {
        "id": "f062297c"
      },
      "source": [
        "# Second Model. Decision Tree without Binned columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "081954a3",
      "metadata": {
        "id": "081954a3",
        "outputId": "d535f5e0-70f6-474a-d29f-cd684c1b73e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target encoding of City:\n",
            "Target encoding of State:\n",
            "Target encoding of Zip:\n",
            "Target encoding of Bank:\n",
            "Target encoding of BankState:\n",
            "Target encoding of NAICS:\n",
            "Onehot encoding of NewExist:\n",
            "Target encoding of FranchiseCode:\n",
            "Onehot encoding of UrbanRural:\n",
            "Onehot encoding of RevLineCr:\n",
            "Onehot encoding of LowDoc:\n",
            "Target encoding of Industry:\n",
            "Class weight  balanced\n",
            "{'ccp_alpha': 0.0, 'max_depth': 20.0} 0.9289014933949413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.95    133561\n",
            "           1       0.72      0.84      0.78     28289\n",
            "\n",
            "    accuracy                           0.92    161850\n",
            "   macro avg       0.84      0.88      0.86    161850\n",
            "weighted avg       0.92      0.92      0.92    161850\n",
            "\n",
            "Class weight  None\n",
            "{'ccp_alpha': 0.0, 'max_depth': 14.0} 0.9383914224316461\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96    133561\n",
            "           1       0.83      0.77      0.80     28289\n",
            "\n",
            "    accuracy                           0.93    161850\n",
            "   macro avg       0.89      0.87      0.88    161850\n",
            "weighted avg       0.93      0.93      0.93    161850\n",
            "\n"
          ]
        }
      ],
      "source": [
        " #Load and Clean, feature engineer data\n",
        "data=pd.read_csv('SBA_loans_project_1.zip')\n",
        "data=clean_data(data)\n",
        "data=feature_engineer(data)\n",
        "#data=bin_numerical_cols(data,drop=False,number_of_bins=40)\n",
        "\n",
        "#Split data\n",
        "X_train,X_test,y_train,y_test=train_test_split(data.drop(columns=['MIS_Status'])\n",
        "                                               ,data['MIS_Status'].values.reshape(-1,1), test_size=0.2, random_state=0)\n",
        "X_train=X_train.reset_index(drop=True)\n",
        "X_test=X_test.reset_index(drop=True)\n",
        "\n",
        "#Encode the categorical variables\n",
        "\n",
        "#Categorical encoders disctionary\n",
        "column_encoders=[]\n",
        "#New categorical (encoded) columns\n",
        "encoded_columns=[]\n",
        "#Columns to drop from ML models\n",
        "columns_to_drop=[]\n",
        "\n",
        "for col in data.drop(columns='MIS_Status').columns:\n",
        "    if data[col].dtype=='object':\n",
        "        if data[col].nunique() <10:\n",
        "            print('Onehot encoding of {}:'.format(col))\n",
        "            enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "            '''Encode Training data'''\n",
        "            enc.fit(X_train[[col]])\n",
        "            result = enc.transform(X_train[[col]])\n",
        "            ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
        "            result_train=pd.DataFrame(enc.transform(X_train[[col]]),columns=ohe_columns)\n",
        "            X_train = pd.concat([X_train, result_train], axis=1)\n",
        "            '''Encode Test data'''\n",
        "            result_test=pd.DataFrame(enc.transform(X_test[[col]]),columns=ohe_columns)\n",
        "            X_test = pd.concat([X_test,result_test],axis=1)\n",
        "            encoded_columns = encoded_columns + ohe_columns \n",
        "            column_encoders.append([deepcopy(enc),'ohe'])\n",
        "        else:\n",
        "            print('Target encoding of {}:'.format(col))\n",
        "            te=TargetEncoder(smoothing=0.1,handle_unknown='value')\n",
        "            '''Fit and transform Training data'''\n",
        "            te.fit(X_train[col],y_train)\n",
        "            new_col=col+'_trg'\n",
        "            X_train[new_col]=te.transform(X_train[col])\n",
        "            '''Transform Test data'''\n",
        "            X_test[new_col]=te.transform(X_test[col])                         \n",
        "            encoded_columns.append(new_col)\n",
        "            column_encoders.append([deepcopy(te),'trg'])\n",
        "            \n",
        "        columns_to_drop.append(col)\n",
        "        \n",
        "# Drop encoded columns\n",
        "X_train.drop(columns=columns_to_drop,inplace=True)\n",
        "X_test.drop(columns=columns_to_drop,inplace=True)\n",
        "\n",
        "# train the model\n",
        "\n",
        "for balance in ['balanced',None]:\n",
        "    print('Class weight ',balance)\n",
        "    parameters={'max_depth':np.linspace(11,20,10),'ccp_alpha':np.linspace(0,0.001,5)}\n",
        "    dtc = DecisionTreeClassifier(criterion='gini',random_state=0,class_weight=balance)\n",
        "    clf = GridSearchCV(dtc, parameters, cv=4,scoring='f1_weighted',n_jobs=-1)\n",
        "    clf.fit(X_train, y_train)\n",
        "    print(clf.best_params_,clf.best_score_)\n",
        "    print(classification_report(y_test,clf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ed974e",
      "metadata": {
        "id": "c8ed974e"
      },
      "source": [
        "# 3. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a1fba59",
      "metadata": {
        "scrolled": true,
        "id": "4a1fba59",
        "outputId": "b3302934-10d2-49af-dfd1-4cf30ca9b0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target encoding of City:\n",
            "Target encoding of State:\n",
            "Target encoding of Zip:\n",
            "Target encoding of Bank:\n",
            "Target encoding of BankState:\n",
            "Target encoding of NAICS:\n",
            "Onehot encoding of NewExist:\n",
            "Target encoding of FranchiseCode:\n",
            "Onehot encoding of UrbanRural:\n",
            "Onehot encoding of RevLineCr:\n",
            "Onehot encoding of LowDoc:\n",
            "Target encoding of Industry:\n",
            "Target encoding of Term_bin:\n",
            "Target encoding of NoEmp_bin:\n",
            "Target encoding of CreateJob_bin:\n",
            "Target encoding of RetainedJob_bin:\n",
            "Target encoding of DisbursementGross_bin:\n",
            "Onehot encoding of BalanceGross_bin:\n",
            "Target encoding of GrAppv_bin:\n",
            "Target encoding of SBA_Appv_bin:\n",
            "Target encoding of monthly_disumb_bin:\n",
            "Training in progress..\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4,\n",
              "             estimator=LogisticRegression(class_weight='balanced',\n",
              "                                          solver='liblinear'),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'C': array([ 0.   ,  0.625,  1.25 ,  1.875,  2.5  ,  3.125,  3.75 ,  4.375,\n",
              "        5.   ,  5.625,  6.25 ,  6.875,  7.5  ,  8.125,  8.75 ,  9.375,\n",
              "       10.   , 10.625, 11.25 , 11.875, 12.5  , 13.125, 13.75 , 14.375,\n",
              "       15.   ]),\n",
              "                         'penalty': ('l1', 'l2')},\n",
              "             scoring='f1_weighted')"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load and manipulate date\n",
        "data=pd.read_csv('SBA_loans_project_1.zip')\n",
        "data=clean_data(data)\n",
        "data=feature_engineer(data)\n",
        "data=bin_numerical_cols(data,drop=True,number_of_bins=40)\n",
        "\n",
        "# #Split data\n",
        "X_train,X_test,y_train,y_test=train_test_split(data.drop(columns=['MIS_Status'])\n",
        "                                               ,data['MIS_Status'].values.reshape(-1,1), test_size=0.2, random_state=0)\n",
        "X_train=X_train.reset_index(drop=True)\n",
        "X_test=X_test.reset_index(drop=True)\n",
        "\n",
        "#Encode the categorical variables\n",
        "#Categorical encoders \n",
        "column_encoders=[]\n",
        "#New categorical (encoded) columns\n",
        "encoded_columns=[]\n",
        "#Columns to drop from ML models\n",
        "columns_to_drop=[]\n",
        "\n",
        "for col in data.drop(columns='MIS_Status').columns:\n",
        "    if data[col].dtype=='object':\n",
        "        if data[col].nunique() <10:\n",
        "            print('Onehot encoding of {}:'.format(col))\n",
        "            enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "            '''Encode Training data'''\n",
        "            enc.fit(X_train[[col]])\n",
        "            result = enc.transform(X_train[[col]])\n",
        "            ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
        "            result_train=pd.DataFrame(enc.transform(X_train[[col]]),columns=ohe_columns)\n",
        "            X_train = pd.concat([X_train, result_train], axis=1)\n",
        "            '''Encode Test data'''\n",
        "            result_test=pd.DataFrame(enc.transform(X_test[[col]]),columns=ohe_columns)\n",
        "            X_test = pd.concat([X_test,result_test],axis=1)\n",
        "            encoded_columns = encoded_columns + ohe_columns \n",
        "            column_encoders.append([deepcopy(enc),'ohe'])\n",
        "        else:\n",
        "            print('Target encoding of {}:'.format(col))\n",
        "            te=TargetEncoder(smoothing=0.1,handle_unknown='value')\n",
        "            '''Fit and transform Training data'''\n",
        "            te.fit(X_train[col],y_train)\n",
        "            new_col=col+'_trg'\n",
        "            X_train[new_col]=te.transform(X_train[col])\n",
        "            '''Transform Test data'''\n",
        "            X_test[new_col]=te.transform(X_test[col])                         \n",
        "            encoded_columns.append(new_col)\n",
        "            column_encoders.append([deepcopy(te),'trg'])\n",
        "            \n",
        "        columns_to_drop.append(col)\n",
        "        \n",
        "# Drop encoded columns\n",
        "X_train.drop(columns=columns_to_drop,inplace=True)\n",
        "X_test.drop(columns=columns_to_drop,inplace=True)\n",
        "\n",
        "# Scale the data\n",
        "scaler=MinMaxScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "\n",
        "print('Training in progress..')\n",
        "# train the model\n",
        "parameters={'C': np.linspace(0,15,25), 'penalty':('l1','l2')}\n",
        "logreg =LogisticRegression(class_weight='balanced',solver='liblinear')\n",
        "clf = GridSearchCV(logreg,param_grid=parameters, cv=4,scoring='f1_weighted',n_jobs=-1)\n",
        "clf.fit(X_train, y_train.ravel())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5c8237d",
      "metadata": {
        "id": "f5c8237d",
        "outputId": "38eab7c2-955c-466c-b742-fa87fba3b72e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8623821842716267 {'C': 0.625, 'penalty': 'l2'}\n"
          ]
        }
      ],
      "source": [
        "print(clf.best_score_,clf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b489bd",
      "metadata": {
        "id": "38b489bd",
        "outputId": "2cc5b72d-f4b7-41ea-9848-ca4f657407a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best threshold is 0.69.\n",
            "Confusion matrix :  [[122342  11219]\n",
            " [  8506  19783]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.93    133561\n",
            "           1       0.64      0.70      0.67     28289\n",
            "\n",
            "    accuracy                           0.88    161850\n",
            "   macro avg       0.79      0.81      0.80    161850\n",
            "weighted avg       0.88      0.88      0.88    161850\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LogisticRegression(class_weight='balanced',solver='liblinear',C=clf.best_params_['C'],penalty=clf.best_params_['penalty'])\n",
        "logreg.fit(X_train,y_train)\n",
        "y_pred=logreg.predict_proba(X_test)\n",
        "threshold=np.linspace(0,1,100)\n",
        "score={}\n",
        "for t in threshold:\n",
        "    pred_class=[1 if i>=t else 0 for i in y_pred[:,1]]\n",
        "    score[t]=f1_score(y_test,pred_class)\n",
        "\n",
        "best_threshold = max(score, key=score.get)\n",
        "pred_class=[1 if i>=best_threshold else 0 for i in y_pred[:,1]]\n",
        "print('Best threshold is {:.2f}.'.format(best_threshold))\n",
        "\n",
        "print('Confusion matrix : ', confusion_matrix(y_test,pred_class))\n",
        "print(classification_report(y_test,pred_class))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3ed601e",
      "metadata": {
        "id": "e3ed601e"
      },
      "source": [
        "## Train final model and save artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c86dbe35",
      "metadata": {
        "id": "c86dbe35"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def train_model(data):\n",
        "    \"\"\"\n",
        "    Train sample model and save artifacts\n",
        "    Flow:\n",
        "        - Clean dataset and do feature engineering (Transfrom)\n",
        "        - Encode columns\n",
        "        - Train model and encoders\n",
        "    \n",
        "    \"\"\"\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    from category_encoders import TargetEncoder\n",
        "    from copy import deepcopy\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    import pickle\n",
        "    \n",
        "    '''Transform data'''\n",
        "    def clean_data(data):\n",
        "        '''\n",
        "        Function to Handle missing and incorrect data \n",
        "\n",
        "        Input: SBA dataframe given by Professor\n",
        "\n",
        "        Output: Cleaned dataframe\n",
        "\n",
        "        '''\n",
        "        #Fill missing valuas\n",
        "        value_to_fill={}\n",
        "        for col in data.columns:\n",
        "            if data[col].dtype=='object':\n",
        "                value_to_fill[col]='Missing'\n",
        "            else:\n",
        "                value_to_fill[col]=0\n",
        "        data.fillna(value=value_to_fill,inplace=True)\n",
        "\n",
        "        #remove dollar sign and convert to numerical\n",
        "        Columns = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
        "        for col in Columns:\n",
        "            for char in ['$',',']:\n",
        "                data[col] = data[col].str.replace(char,'')\n",
        "            data[col]=data[col].astype(float)\n",
        "\n",
        "        #LowDoc and RevLineCr can only be 'Y' or 'N', i.e., yes or no.\n",
        "        for col in ['LowDoc' , 'RevLineCr']:\n",
        "            data[col]=data[col].agg(lambda x: 'Missing' if x not in ['N','Y'] else x)\n",
        "\n",
        "        # NAICS code must be 6 digit code: replace smaller digits with 0.\n",
        "        data['NAICS']=data['NAICS'].agg(lambda x: x if len(str(x))==6 else 0)\n",
        "\n",
        "        # Franchise code 0 and 1 means 'NO Franchise'\n",
        "        data['FranchiseCode']=data['FranchiseCode'].agg(lambda x: 1 if x==1 else x)\n",
        "\n",
        "        # Convert NAICS, FranchaiseCode, Zip,'NewExist' and 'UrbanRural' into object type\n",
        "        for col in ['FranchiseCode','NAICS','Zip','NewExist','UrbanRural']:\n",
        "            data[col]=data[col].astype(object)\n",
        "            \n",
        "        #Convert MIS into binary\n",
        "        MIS_dict={'P I F': 0, 'CHGOFF': 1,'Missing':0}\n",
        "        data['MIS_Status'].replace(MIS_dict,inplace=True)\n",
        "        return(data)\n",
        "\n",
        "    def feature_engineer(data):\n",
        "        ''' Creates two new features: Industry and Montly_disumbersement.\n",
        "            Input: Cleaned SBA Dataframe\n",
        "            Output: Dataframe with feature engineered columns\n",
        "        '''\n",
        "        industry_codes=['11','21','22','23','31','32','33','42','44','45','48','49','51',\n",
        "                        '52','53','54','55','56','61','62','71','72','81','0']\n",
        "        industry_dict={'11':'Agriculture, forestry, fishing and hunting',\n",
        "            '21':'Mining, quarrying, and oil and gas extraction',\n",
        "            '22':'Utilities',\n",
        "            '23':'Construction',\n",
        "            '31':'Manufacturing',\n",
        "            '32':'Manufacturing',\n",
        "            '33':'Manufacturing',\n",
        "            '42':'Wholesale trade',\n",
        "            '44':'Retail trade',\n",
        "            '45':'Retail trade',\n",
        "            '48':'Transportation and warehousing',\n",
        "            '49':'Transportation and warehousing',\n",
        "            '51':'Information',\n",
        "            '52':'Finance and insurance',\n",
        "            '53':'Real estate and rental and leasing',\n",
        "            '54':'Professional, scientific, and technical services',\n",
        "            '55':'Management of companies and enterprises',\n",
        "            '56':'Administrative and support and waste management and remediation services',\n",
        "            '61':'Educational services',\n",
        "            '62':'Health care and social assistance',\n",
        "            '71':'Arts, entertainment, and recreation',\n",
        "            '72':'Accommodation and food services',\n",
        "            '81':'Other services (except public administration) 92 Public administration',\n",
        "            '0':'undefined'}\n",
        "        # Function to create Industry column from NAICS columns\n",
        "        def add_Industry_col(data):\n",
        "            data['Industry']=data['NAICS'].astype('string')\n",
        "            data['Industry']=data['Industry'].apply(lambda x: x[:2] if x[:2] in industry_codes else  x=='0' )\n",
        "            data['Industry'].replace(industry_dict,inplace=True)\n",
        "            return data\n",
        "\n",
        "\n",
        "        # Function to create monthtly disumbersement column.\n",
        "        def monthly_payment(total,terms):\n",
        "            if terms==0:\n",
        "                monthly=total\n",
        "            else:\n",
        "                monthly=total/terms\n",
        "            return monthly\n",
        "        data= add_Industry_col(data)\n",
        "        data['monthly_disumb'] = data.apply(lambda x: monthly_payment(x.DisbursementGross, x.Term), axis=1)\n",
        "\n",
        "        return data\n",
        "\n",
        "    #Apply defined functions to clean data and create new features\n",
        "    data=clean_data(data)\n",
        "    data=feature_engineer(data)\n",
        "    \n",
        "    '''Train model and encoders'''\n",
        "    y = data['MIS_Status']\n",
        "    X = data.drop(columns=['MIS_Status'])\n",
        "    cat_encoders = {}\n",
        "    drop_columns = []\n",
        "    enc_columns=[]\n",
        "    for col in X.columns:\n",
        "        if X[col].dtype=='object':\n",
        "            if X[col].nunique() <10:\n",
        "                enc = OneHotEncoder(handle_unknown='ignore')\n",
        "                '''Encode Training data'''\n",
        "                enc.fit(X[col].values.reshape(-1,1))\n",
        "                result = enc.transform(X[col].values.reshape(-1,1)).toarray()\n",
        "                ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
        "                result_train=pd.DataFrame(result,columns=ohe_columns)\n",
        "                result_train.index=X.index\n",
        "                X[ohe_columns]=result_train\n",
        "                cat_encoders[col] = [deepcopy(enc),\"ohe\"]\n",
        "                enc_columns.append(col)\n",
        "            else:\n",
        "                te=TargetEncoder(smoothing=0.1,handle_unknown='value')\n",
        "                '''Fit and transform Training data'''\n",
        "                te.fit(X[[col]],y)\n",
        "                new_col=col+'_trg'\n",
        "                X[new_col]=te.transform(X[col])                         \n",
        "                cat_encoders[col] = [deepcopy(te),\"te\"]\n",
        "                enc_columns.append(col)\n",
        "            drop_columns.append(col)\n",
        "  \n",
        "    clf = DecisionTreeClassifier(criterion='gini',random_state=0, ccp_alpha=0, max_depth=14,class_weight=None)\n",
        "    X=X.drop(columns=drop_columns)\n",
        "    clf.fit(X, y)\n",
        "    \n",
        "    decision_tree_file = open(\"decision_tree_model.pkl\", \"wb\")\n",
        "    encoders_file = open(\"decision_tree_encoders.pkl\", \"wb\")\n",
        "    pickle.dump(obj=clf, file=decision_tree_file)\n",
        "    pickle.dump(obj=cat_encoders, file=encoders_file)\n",
        "    \n",
        "    decision_tree_file.close()\n",
        "    encoders_file.close()\n",
        "    \n",
        "    return clf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1929ab",
      "metadata": {
        "id": "ae1929ab"
      },
      "outputs": [],
      "source": [
        "def project_1_scoring(data):\n",
        "    \"\"\"\n",
        "    Function to score input dataset.\n",
        "    \n",
        "    Input: dataset in Pandas DataFrame format\n",
        "    Output: Python list of labels in the same order as input records\n",
        "    \n",
        "    Flow:\n",
        "        - Load artifacts\n",
        "        - Transform dataset\n",
        "        - Score dataset\n",
        "        - Return labels\n",
        "    \n",
        "    \"\"\"\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    from copy import deepcopy\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    import pickle\n",
        "    \n",
        "    '''Clean and feature engineer'''\n",
        "    def clean_data(data):\n",
        "        '''\n",
        "        Function to Handle missing and incorrect data \n",
        "\n",
        "        Input: SBA dataframe given by Professor\n",
        "\n",
        "        Output: Cleaned dataframe\n",
        "\n",
        "        '''\n",
        "        #Fill missing valuas\n",
        "        value_to_fill={}\n",
        "        for col in data.columns:\n",
        "            if data[col].dtype=='object':\n",
        "                value_to_fill[col]='Missing'\n",
        "            else:\n",
        "                value_to_fill[col]=0\n",
        "        data.fillna(value=value_to_fill,inplace=True)\n",
        "\n",
        "        #remove dollar sign and convert to numerical\n",
        "        Columns = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
        "        for col in Columns:\n",
        "            for char in ['$',',']:\n",
        "                data[col] = data[col].str.replace(char,'')\n",
        "            data[col]=data[col].astype(float)\n",
        "\n",
        "        #LowDoc and RevLineCr can only be 'Y' or 'N', i.e., yes or no.\n",
        "        for col in ['LowDoc' , 'RevLineCr']:\n",
        "            data[col]=data[col].agg(lambda x: 'Missing' if x not in ['N','Y'] else x)\n",
        "\n",
        "        # NAICS code must be 6 digit code: replace smaller digits with 0.\n",
        "        data['NAICS']=data['NAICS'].agg(lambda x: x if len(str(x))==6 else 0)\n",
        "\n",
        "        # Franchise code 0 and 1 means 'NO Franchise'\n",
        "        data['FranchiseCode']=data['FranchiseCode'].agg(lambda x: 1 if x==1 else x)\n",
        "\n",
        "        # Convert NAICS, FranchaiseCode, Zip,'NewExist' and 'UrbanRural' into object type\n",
        "        for col in ['FranchiseCode','NAICS','Zip','NewExist','UrbanRural']:\n",
        "            data[col]=data[col].astype(object)\n",
        "        \n",
        "        return(data)\n",
        "\n",
        "    def feature_engineer(data):\n",
        "        ''' Creates two new features: Industry and Montly_disumbersement.\n",
        "            Input: Cleaned SBA Dataframe\n",
        "            Output: Dataframe with feature engineered columns\n",
        "        '''\n",
        "        industry_codes=['11','21','22','23','31','32','33','42','44','45','48','49','51',\n",
        "                        '52','53','54','55','56','61','62','71','72','81','0']\n",
        "        industry_dict={'11':'Agriculture, forestry, fishing and hunting',\n",
        "            '21':'Mining, quarrying, and oil and gas extraction',\n",
        "            '22':'Utilities',\n",
        "            '23':'Construction',\n",
        "            '31':'Manufacturing',\n",
        "            '32':'Manufacturing',\n",
        "            '33':'Manufacturing',\n",
        "            '42':'Wholesale trade',\n",
        "            '44':'Retail trade',\n",
        "            '45':'Retail trade',\n",
        "            '48':'Transportation and warehousing',\n",
        "            '49':'Transportation and warehousing',\n",
        "            '51':'Information',\n",
        "            '52':'Finance and insurance',\n",
        "            '53':'Real estate and rental and leasing',\n",
        "            '54':'Professional, scientific, and technical services',\n",
        "            '55':'Management of companies and enterprises',\n",
        "            '56':'Administrative and support and waste management and remediation services',\n",
        "            '61':'Educational services',\n",
        "            '62':'Health care and social assistance',\n",
        "            '71':'Arts, entertainment, and recreation',\n",
        "            '72':'Accommodation and food services',\n",
        "            '81':'Other services (except public administration) 92 Public administration',\n",
        "            '0':'undefined'}\n",
        "        # Function to create Industry column from NAICS columns\n",
        "        def add_Industry_col(data):\n",
        "            data['Industry']=data['NAICS'].astype('string')\n",
        "            data['Industry']=data['Industry'].apply(lambda x: x[:2] if x[:2] in industry_codes else  x=='0' )\n",
        "            data['Industry'].replace(industry_dict,inplace=True)\n",
        "            return data\n",
        "\n",
        "\n",
        "        # Function to create monthtly disumbersement column.\n",
        "        def monthly_payment(total,terms):\n",
        "            if terms==0:\n",
        "                monthly=total\n",
        "            else:\n",
        "                monthly=total/terms\n",
        "            return monthly\n",
        "        data= add_Industry_col(data)\n",
        "        data['monthly_disumb'] = data.apply(lambda x: monthly_payment(x.DisbursementGross, x.Term), axis=1)\n",
        "\n",
        "        return data\n",
        "\n",
        "    #Apply defined functions to clean data and create new features\n",
        "    data=clean_data(data)\n",
        "    data=feature_engineer(data)\n",
        "   \n",
        "    X = data.copy()\n",
        "    ohe_columns = ['City',\n",
        "                 'State',\n",
        "                 'Zip',\n",
        "                 'Bank',\n",
        "                 'BankState',\n",
        "                 'NAICS',\n",
        "                 'NewExist',\n",
        "                 'FranchiseCode',\n",
        "                 'UrbanRural',\n",
        "                 'RevLineCr',\n",
        "                 'LowDoc',\n",
        "                 'Industry']\n",
        "    \n",
        "    '''Load Model and encoder'''\n",
        "    decision_tree_file = open(\"decision_tree_model.pkl\", \"rb\")\n",
        "    encoders_file = open(\"decision_tree_encoders.pkl\", \"rb\")\n",
        "    \n",
        "    clf = pickle.load(file=decision_tree_file)\n",
        "    enc_dict = pickle.load(encoders_file)\n",
        "    drop_columns = []\n",
        "    \n",
        "    '''Encode categorical columns'''\n",
        "    for col in ohe_columns:\n",
        "        if enc_dict[col][1]=='ohe':\n",
        "            enc = enc_dict[col][0]\n",
        "            result = enc.transform(X[[col]].values.reshape(-1,1)).toarray()\n",
        "            ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
        "            result_train = pd.DataFrame(result, columns=ohe_columns)\n",
        "            result_train.index=X.index\n",
        "            X[ohe_columns]=result_train\n",
        "        else:\n",
        "            new_col=col+'_trg'\n",
        "            te = enc_dict[col][0]\n",
        "            X[new_col]=te.transform(X[col])   \n",
        "        drop_columns.append(col)\n",
        "    X=X.drop(columns=drop_columns)  \n",
        "    y_pred = clf.predict(X)\n",
        "    \n",
        "    decision_tree_file.close()\n",
        "    encoders_file.close()\n",
        "    \n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea3ada20",
      "metadata": {
        "id": "ea3ada20"
      },
      "source": [
        "# Example use of the train and scoring function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62d554e3",
      "metadata": {
        "id": "62d554e3",
        "outputId": "a54c966b-4796-4fb4-9649-3465eed9a8ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96     66678\n",
            "           1       0.83      0.77      0.80     14247\n",
            "\n",
            "    accuracy                           0.93     80925\n",
            "   macro avg       0.89      0.87      0.88     80925\n",
            "weighted avg       0.93      0.93      0.93     80925\n",
            "\n",
            "[[64395  2283]\n",
            " [ 3242 11005]]\n",
            "F1 score =  0.9307817189649107\n",
            "Roc-Auc score =  0.8691020710307422\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('SBA_loans_project_1.zip')\n",
        "df_1,df_2 = train_test_split(data,test_size=0.1,random_state=42)\n",
        "\n",
        "df_3=df_2 # will be use to get actual class\n",
        "\n",
        "df_2 = df_2.drop(columns='MIS_Status')\n",
        "clf=train_model(df_1)\n",
        "estimate=project_1_scoring(df_2)\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix,f1_score,roc_auc_score\n",
        "target=clean_data(df_3)['MIS_Status']\n",
        "print(classification_report(target,estimate))\n",
        "print(confusion_matrix(target,estimate))\n",
        "print('F1 score = ',f1_score(target,estimate,average='weighted'))\n",
        "print('Roc-Auc score = ',roc_auc_score(target,estimate))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}